{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b53caf6-8c2f-4e7d-b3a4-597cf0238640",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import Tuple\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "719362e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_data = pd.read_csv(\"../dataset/A_Z Handwritten Data.csv\")[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833032ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_data.to_csv(\"../dataset/alpha_data_10000.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3dd0777-3517-4f1f-9527-5e8ffb87e48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist_data(dataset_path: str) -> Tuple[np.array]:\n",
    "    mnist_dataset = np.load(dataset_path, allow_pickle=True)\n",
    "    x_train = mnist_dataset[\"x_train\"]\n",
    "    y_train = mnist_dataset[\"y_train\"]\n",
    "\n",
    "    x_test = mnist_dataset[\"x_test\"]\n",
    "    y_test = mnist_dataset[\"y_test\"]\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7eee7335",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    # MNIST Data\n",
    "    digit_image_train, digit_label_train, digit_image_test, digit_label_test = load_mnist_data(\"../dataset/mnist.npz\")\n",
    "    digit_label = np.hstack((digit_label_train, digit_label_test))\n",
    "    digit_image = np.vstack((digit_image_train, digit_image_test))\n",
    "\n",
    "    #A-Z Data\n",
    "    alpha_data = pd.read_csv(\"../dataset/A_Z Handwritten Data.csv\")\n",
    "    alpha_label = np.array(alpha_data[\"0\"])  # The '0' column is the target\n",
    "    alpha_label += 10  # A-Z will not overlab with MNIST\n",
    "    alpha_image = alpha_data.drop([\"0\"], axis=1)  # Drop target column\n",
    "    alpha_image = np.reshape(\n",
    "        alpha_image.values,\n",
    "        (alpha_image.shape[0], 28, 28)\n",
    "    ) # Resize to (28*28)\n",
    "\n",
    "    # Combine datasets\n",
    "    labels = np.hstack((digit_label, alpha_label))\n",
    "    data = np.vstack((digit_image, alpha_image))\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "690fefc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (442450, 28, 28)\n",
      "Labels shape: (442450,)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "data, labels = load_data()\n",
    "print(f'Data shape: {data.shape}')\n",
    "print(f'Labels shape: {labels.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6223b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Train test splits\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    data,\n",
    "    labels,\n",
    "    test_size=0.20,\n",
    "    stratify=labels,\n",
    "    random_state=101\n",
    ")\n",
    "\n",
    "# Delete data\n",
    "del data, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d315d68a",
   "metadata": {},
   "source": [
    "<h1>Create dataloader</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932756ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec491412",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(\n",
    "    images: np.array, \n",
    "    labels: np.array,\n",
    "    batch_size: int = 32\n",
    ") -> DataLoader:\n",
    "    images = torch.tensor(images, dtype=torch.float32).unsqueeze(1)  # Shape: (total, 1, 28, 28)\n",
    "\n",
    "    # Convert labels to tensors\n",
    "    labels = torch.tensor(labels, dtype=torch.long)  # Shape: (total,)\n",
    "\n",
    "    # Create a Dataset and DataLoader\n",
    "    dataset = TensorDataset(images, labels)\n",
    "\n",
    "    # Use DataLoader for batching and shuffling\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df49af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_dataloader = get_dataloader(images=x_train, labels=y_train, batch_size=batch_size)\n",
    "test_dataloader = get_dataloader(images=x_test, labels=y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b077afe9",
   "metadata": {},
   "source": [
    "<h1>Build model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015b7f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "\n",
    "class TextRecognitionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TextRecognitionModel, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(3, 3), stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 3), stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Dropout(0.15),\n",
    "\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3, 3), stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Dropout(0.1),\n",
    "\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=64, out_features=64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=64, out_features=36)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad264e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TextRecognitionModel().to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8030f2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01d79b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def eval(\n",
    "    val_dataloader: DataLoader, \n",
    "    model: nn.Module, \n",
    "    loss_function: torch.nn.modules.loss,\n",
    "    device: torch.device\n",
    ") -> float:\n",
    "    num_batches = len(val_dataloader)\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_dataloader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            pred = model(images)\n",
    "            test_loss = loss_function(pred, labels).item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    return test_loss\n",
    "\n",
    "\n",
    "def train(\n",
    "    train_dataloader: DataLoader,\n",
    "    val_dataloader: DataLoader,\n",
    "    model: nn.Module,\n",
    "    loss_function: torch.nn.modules.loss,\n",
    "    optimizer: torch.optim,\n",
    "    device: torch.device,\n",
    "    model_dir: str,\n",
    "    eval_every: int = 1,\n",
    "    epochs: int = 50\n",
    "):\n",
    "    def batch_train(\n",
    "        images: DataLoader, \n",
    "        labels: DataLoader,\n",
    "        model: TextRecognitionModel,\n",
    "        loss_function,\n",
    "        optimizer,\n",
    "        device: torch.device\n",
    "    ):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        pred = model(images)\n",
    "\n",
    "        loss = loss_function(pred, labels)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "\n",
    "    min_loss = None\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        for _, (images, labels) in enumerate(train_dataloader):\n",
    "            batch_train(\n",
    "                images=images,\n",
    "                labels=labels,\n",
    "                model=model,\n",
    "                loss_function=loss_function,\n",
    "                optimizer=optimizer,\n",
    "                device=device\n",
    "            )\n",
    "        \n",
    "        if epoch + 1 == eval_every:\n",
    "            test_loss = eval(\n",
    "                val_dataloader=val_dataloader,\n",
    "                model=model,\n",
    "                loss_function=loss_function,\n",
    "                device=device\n",
    "            )\n",
    "\n",
    "            if min_loss is None or test_loss < min_loss:\n",
    "                min_loss = test_loss\n",
    "                torch.save(model.state_dict(), os.path.join(model_dir, \"model.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665a2afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "learning_rate = 1e-3\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f60618",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloader=test_dataloader,\n",
    "    model=model,\n",
    "    loss_function=loss,\n",
    "    optimizer=optimizer,\n",
    "    device=\"cpu\",\n",
    "    model_dir=\"../models/\",\n",
    "    eval_every=1,\n",
    "    epochs=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f085668d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
